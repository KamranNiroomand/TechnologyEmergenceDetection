{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2b0b80-0f75-453c-83b9-ee0af6e138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import progressbar\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69d917c-781a-4ecd-88f2-fe3515bf0320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.7.1\n",
      "jupyter-notebook : 6.3.0\n",
      "qtconsole        : not installed\n",
      "ipython          : 7.16.1\n",
      "ipykernel        : 5.3.4\n",
      "jupyter client   : 7.0.2\n",
      "jupyter lab      : 3.2.2\n",
      "nbconvert        : 5.6.1\n",
      "ipywidgets       : 7.6.5\n",
      "nbformat         : 5.1.3\n",
      "traitlets        : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd9d6c-04c2-42b8-96d4-81706c752bba",
   "metadata": {},
   "source": [
    "# 1. Read processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a529e3-8ca5-40b1-92d6-8ff170e9849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7925, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Titles</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Authors with affiliations</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Indexed Keywords</th>\n",
       "      <th>EID</th>\n",
       "      <th>Funding Details</th>\n",
       "      <th>Funding Texts</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>text</th>\n",
       "      <th>lower_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>Energy Efficient Layered Cluster Head Rotation...</td>\n",
       "      <td>Energy efficiency is of paramount concern in u...</td>\n",
       "      <td>Datta A.; Dasgupta M.</td>\n",
       "      <td>Datta A., Department of Computer Applications,...</td>\n",
       "      <td>Cluster-head; Energy consumption; Routing prot...</td>\n",
       "      <td>Energy efficiency; Internet protocols; Network...</td>\n",
       "      <td>2-s2.0-85128393697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Energy Efficient Layered Cluster Head Rotation...</td>\n",
       "      <td>energy efficient layered cluster head rotation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Underwater object detection using collaborativ...</td>\n",
       "      <td>Despite recent progress in deep learning, unde...</td>\n",
       "      <td>Cai S.; Li G.; Shan Y.</td>\n",
       "      <td>Cai S., School of Applied Science, Beijing Inf...</td>\n",
       "      <td>Collaborative learning; Noisy samples; Underwa...</td>\n",
       "      <td>Benchmarking; Deep learning; Object recognitio...</td>\n",
       "      <td>2-s2.0-85132754967</td>\n",
       "      <td>National Natural Science Foundation of China, ...</td>\n",
       "      <td>This work was supported by the National Natura...</td>\n",
       "      <td>Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Underwater object detection using collaborativ...</td>\n",
       "      <td>underwater object detection using collaborativ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                             Titles  \\\n",
       "0  2022  Energy Efficient Layered Cluster Head Rotation...   \n",
       "1  2022  Underwater object detection using collaborativ...   \n",
       "\n",
       "                                            Abstract                 Authors  \\\n",
       "0  Energy efficiency is of paramount concern in u...   Datta A.; Dasgupta M.   \n",
       "1  Despite recent progress in deep learning, unde...  Cai S.; Li G.; Shan Y.   \n",
       "\n",
       "                           Authors with affiliations  \\\n",
       "0  Datta A., Department of Computer Applications,...   \n",
       "1  Cai S., School of Applied Science, Beijing Inf...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Cluster-head; Energy consumption; Routing prot...   \n",
       "1  Collaborative learning; Noisy samples; Underwa...   \n",
       "\n",
       "                                    Indexed Keywords                 EID  \\\n",
       "0  Energy efficiency; Internet protocols; Network...  2-s2.0-85128393697   \n",
       "1  Benchmarking; Deep learning; Object recognitio...  2-s2.0-85132754967   \n",
       "\n",
       "                                     Funding Details  \\\n",
       "0                                                NaN   \n",
       "1  National Natural Science Foundation of China, ...   \n",
       "\n",
       "                                       Funding Texts Document Type  \\\n",
       "0                                                NaN       Article   \n",
       "1  This work was supported by the National Natura...       Article   \n",
       "\n",
       "  Open Access                                               text  \\\n",
       "0         NaN  Energy Efficient Layered Cluster Head Rotation...   \n",
       "1         NaN  Underwater object detection using collaborativ...   \n",
       "\n",
       "                                          lower_text  \n",
       "0  energy efficient layered cluster head rotation...  \n",
       "1  underwater object detection using collaborativ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/Processed/Sent to Kamran/data.csv', encoding='latin1')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b39228-8466-4b25-b3e4-22848eec9199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011, 2022)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Year.min(), df.Year.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67915b17-03c9-4390-abb2-27a07223af65",
   "metadata": {},
   "source": [
    "# 2. Create annual data chunks\n",
    "* from 1990 to 2021, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04719694-f7c2-47e5-884e-f1d70f998943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 size: (340, 14)\n",
      "2012 size: (424, 14)\n",
      "2013 size: (428, 14)\n",
      "2014 size: (482, 14)\n",
      "2015 size: (601, 14)\n",
      "2016 size: (607, 14)\n",
      "2017 size: (618, 14)\n",
      "2018 size: (758, 14)\n",
      "2019 size: (950, 14)\n",
      "2020 size: (896, 14)\n",
      "2021 size: (1047, 14)\n",
      "2022 size: (774, 14)\n"
     ]
    }
   ],
   "source": [
    "for year in range(2011, 2023):\n",
    "    variable_name = \"df_\" + str(year)\n",
    "    locals()[variable_name] = df[df.Year == year]\n",
    "    print(\"%d size: %s\" %(year, locals()[variable_name].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17897a42-bbec-4acb-a12a-c4bdebe89f44",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Keyword extraction using KeyBERT\n",
    "* from: https://towardsdatascience.com/keyword-extraction-python-tf-idf-textrank-topicrank-yake-bert-7405d51cd839\n",
    "* KeyBERT repo: https://github.com/MaartenGr/KeyBERT\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based model for natural language processing. Pretrained models can transform sentences or words in language representation consisting of an array of numbers (embedding). Sentences or words having similar latent representations (embedding) should have similar semantic meanings. An implementation that uses this approach to extract the keywords of a text is KeyBERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b368cb8-2e33-4631-a45f-6483c8ea83f0",
   "metadata": {},
   "source": [
    "## 3.1. Annual, up to 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281fe84b-2a89-4300-b525-94a507d2b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ngram_size = 3  \n",
    "numOfKeywords = 500\n",
    "diversity = 0.5 # parameter to diversify the results, we can use Maximal Margin Relevance (MMR) to create keywords / keyphrases which is based on cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f65d07-cda9-45e9-bf06-dba6a7492bfd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (2 of 17) |#              | Elapsed Time: 22:00:41 ETA:  12 days, 14:10:48"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a843e28ee417>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2022\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mvariable_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"df_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mkeywords_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyphrase_ngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_ngram_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_mmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiversity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumOfKeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Results/Phase 2/KeyBERT/keywords_0.5div_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emerging_tech\\lib\\site-packages\\keybert\\_model.py\u001b[0m in \u001b[0;36mextract_keywords\u001b[1;34m(self, docs, candidates, keyphrase_ngram_range, stop_words, top_n, min_df, use_maxsum, use_mmr, diversity, nr_candidates, vectorizer, highlight, seed_keywords)\u001b[0m\n\u001b[0;32m    121\u001b[0m                                                          \u001b[0mnr_candidates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnr_candidates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                                                          \u001b[0mvectorizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                                                          seed_keywords=seed_keywords)\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mhighlight_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emerging_tech\\lib\\site-packages\\keybert\\_model.py\u001b[0m in \u001b[0;36m_extract_keywords_single_doc\u001b[1;34m(self, doc, candidates, keyphrase_ngram_range, stop_words, top_n, use_maxsum, use_mmr, diversity, nr_candidates, vectorizer, seed_keywords)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;31m# Calculate distances and extract keywords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0muse_mmr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                 \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0muse_maxsum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_sum_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emerging_tech\\lib\\site-packages\\keybert\\_mmr.py\u001b[0m in \u001b[0;36mmmr\u001b[1;34m(doc_embedding, word_embeddings, words, top_n, diversity)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# between candidates and selected keywords/phrases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mcandidate_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_doc_similarity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcandidates_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mtarget_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_similarity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcandidates_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeywords_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Calculate MMR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT  #!pip install keybert\n",
    "\n",
    "progress = progressbar.ProgressBar(max_value=len(range(2011,2023))) \n",
    "\n",
    "try:\n",
    "    # create the keyword extractor\n",
    "    kw_model = KeyBERT()\n",
    "    \n",
    "    for year in progress(range(2011, 2023)):\n",
    "        variable_name = \"df_\" + str(year)\n",
    "        keywords_bert = kw_model.extract_keywords(' '.join(locals()[variable_name].text).lower(), keyphrase_ngram_range=(1,max_ngram_size), stop_words='english', use_mmr=True, diversity=diversity, top_n=numOfKeywords)\n",
    "        \n",
    "        # need to create the \"Results\" folder...\n",
    "        with open('../Results/keywords_0.5div_' + str(year) + '.csv', 'w', encoding=\"utf-8\") as out_file:\n",
    "            out_file.write('Keyword,Score\\n')\n",
    "            for keyword in keywords_bert:\n",
    "                line_to_write = str(keyword[0]) + ',' + str(keyword[1]) + '\\n'\n",
    "                out_file.write(line_to_write)\n",
    "except UnicodeEncodeError as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emerging_Tech (py3.6)",
   "language": "python",
   "name": "emerging_tech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
